{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"imdb_LSTM_sigmoid.ipynb의 사본","version":"0.3.2","provenance":[{"file_id":"https://github.com/loinsir/Keras_Study/blob/master/imdb_LSTM_sigmoid.ipynb","timestamp":1564998567438}]}},"cells":[{"cell_type":"code","metadata":{"id":"rUP4PijuICaR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"80bc0df9-457c-4712-c061-1cdae0b7df59","executionInfo":{"status":"ok","timestamp":1564997615380,"user_tz":-540,"elapsed":2323,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"smRpbq99ICaW","colab_type":"text"},"source":["# IMDB 데이터 셋\n","\n","### 데이터셋 정보\n","- 훈련 데이터와 테스트 데이터가 각각 25000개\n","- 데이터의 각 review에는 label이 붙어 있다.\n","- 부정은 0, 긍정은 1로 나타낸다.\n","- 약 50%는 긍정, 50%는 부정 리뷰로 구성\n","- review 문장의 단어들을 출현빈도순으로 정렬해서 정수로 변환시킨 시퀀스를 x로 한다.\n","- 스탠포드 대학의 앤드류 마스가 수집했다.\n","\n","### 예측하고자 하는 방법\n","- 이진 분류 문제로, 학습 데이터를 이용해, 설계한 신경망을 학습시킨다.\n","- 학습된 신경망을 이용해 어떤 리뷰가 긍정일 확률을 예측할 수 있도록 한다.\n","\n","### 학습을 위해 데이터가 어떻게 가공/처리 되었는지?\n","- 25000개의 샘플을 훈련셋 20000개와 5000개의 검증셋으로 분리\n","- 길이를 맞추기 위해 패딩 삽입\n","- 임베딩 층을 통과하여 실수 텐서로 매핑\n","- LSTM층, Dense층을 차례로 통과하며 모델 훈련\n","\n","### 사용된 모델의 입력층과 출력층\n","- 입력층\n","    - 숫자 인덱스를 밀집 벡터로 매핑하는 embedding층\n","    - (샘플, 시퀀스길이)를 입력 인자로 받음\n","    - 크기가 (샘플, 시퀀스 길이, 임베딩 차원)인 3D 실수 텐서를 출력함.\n","- 출력층\n","    - 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 출력층\n","    - 확률(0과 1 사이의 점수, 1에 가까울수록 긍정, 0에 가까울 수록 부정)을 출력하기 위해 시그모이드 활성화 함수(로지스틱 함수, vanishing gradient 문제가 있어서 현재는 잘 사용하지 않음)를 사용\n","\n","###  사용된 모델의 특징에 대한 기술 \n","- rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 컴파일.\n","- LSTM 층으로 모델을 구성하여 기존의 완전연결 네트워크보다 나은 결과를 기대.\n","- 다만 하이퍼파라미터를 지정하지 않았으므로(기본값 사용) 매우 큰 차이는 기대하기 힘듬."]},{"cell_type":"code","metadata":{"id":"BtUQwWaAICaY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"0363d179-44c4-42a6-f57f-4543875086df","executionInfo":{"status":"ok","timestamp":1564997627556,"user_tz":-540,"elapsed":7768,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["from keras.datasets import imdb\n","import numpy as np\n","\n","np_load_old = np.load\n","np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n","(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=20000)\n","\n","np.load = np_load_old"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n","17465344/17464789 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rwsccIMnICaa","colab_type":"code","colab":{}},"source":["max_features = 20000\n","text_max_words = 200\n","\n","#훈련셋, 검증셋 지정\n","input_val = input_train[max_features:]\n","y_val = y_train[max_features:]\n","input_train = input_train[:max_features]\n","y_train = y_train[:max_features]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8GdWdIyICac","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e3f3d5e6-c103-44cb-f7c9-7981af0e9eed","executionInfo":{"status":"ok","timestamp":1564998339709,"user_tz":-540,"elapsed":696207,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense\n","from keras.preprocessing import sequence\n","\n","input_train = sequence.pad_sequences(input_train, maxlen=text_max_words)\n","input_val = sequence.pad_sequences(input_val, maxlen=text_max_words)\n","input_test = sequence.pad_sequences(input_test, maxlen=text_max_words)\n","\n","model = Sequential()\n","model.add(Embedding(max_features, 32))\n","model.add(LSTM(32))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","history = model.fit(input_train, y_train,\n","                    epochs=25,\n","                    batch_size=128,\n","                    )\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0805 09:34:04.541151 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0805 09:34:04.572379 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0805 09:34:04.578877 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0805 09:34:04.847630 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0805 09:34:04.870087 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0805 09:34:04.879209 139774824560512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0805 09:34:05.981781 139774824560512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.4860 - acc: 0.7752\n","Epoch 2/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.2735 - acc: 0.8937\n","Epoch 3/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.2089 - acc: 0.9221\n","Epoch 4/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.1653 - acc: 0.9414\n","Epoch 5/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.1368 - acc: 0.9523\n","Epoch 6/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.1179 - acc: 0.9602\n","Epoch 7/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.0980 - acc: 0.9669\n","Epoch 8/25\n","20000/20000 [==============================] - 27s 1ms/step - loss: 0.0875 - acc: 0.9715\n","Epoch 9/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0744 - acc: 0.9751\n","Epoch 10/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0650 - acc: 0.9794\n","Epoch 11/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0579 - acc: 0.9811\n","Epoch 12/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0484 - acc: 0.9848\n","Epoch 13/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0454 - acc: 0.9850\n","Epoch 14/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0399 - acc: 0.9881\n","Epoch 15/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0374 - acc: 0.9890\n","Epoch 16/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0329 - acc: 0.9905\n","Epoch 17/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0304 - acc: 0.9906\n","Epoch 18/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0272 - acc: 0.9922\n","Epoch 19/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0233 - acc: 0.9931\n","Epoch 20/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0276 - acc: 0.9928\n","Epoch 21/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0209 - acc: 0.9938\n","Epoch 22/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0196 - acc: 0.9944\n","Epoch 23/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0204 - acc: 0.9937\n","Epoch 24/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0150 - acc: 0.9959\n","Epoch 25/25\n","20000/20000 [==============================] - 28s 1ms/step - loss: 0.0153 - acc: 0.9950\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 32)          640000    \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 32)                8320      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 648,353\n","Trainable params: 648,353\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}