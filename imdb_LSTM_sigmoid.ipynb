{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 데이터 셋\n",
    "\n",
    "### 데이터셋 정보\n",
    "- 훈련 데이터와 테스트 데이터가 각각 25000개\n",
    "- 데이터의 각 review에는 label이 붙어 있다.\n",
    "- 부정은 0, 긍정은 1로 나타낸다.\n",
    "- 약 50%는 긍정, 50%는 부정 리뷰로 구성\n",
    "- review 문장의 단어들을 출현빈도순으로 정렬해서 정수로 변환시킨 시퀀스를 x로 한다.\n",
    "- 스탠포드 대학의 앤드류 마스가 수집했다.\n",
    "\n",
    "### 예측하고자 하는 방법\n",
    "- 이진 분류 문제로, 학습 데이터를 이용해, 설계한 신경망을 학습시킨다.\n",
    "- 학습된 신경망을 이용해 어떤 리뷰가 긍정일 확률을 예측할 수 있도록 한다.\n",
    "\n",
    "### 학습을 위해 데이터가 어떻게 가공/처리 되었는지?\n",
    "- 25000개의 샘플을 훈련셋 20000개와 5000개의 검증셋으로 분리\n",
    "- 길이를 맞추기 위해 패딩 삽입\n",
    "- 임베딩 층을 통과하여 실수 텐서로 매핑\n",
    "- LSTM층, Dense층을 차례로 통과하며 모델 훈련\n",
    "\n",
    "### 사용된 모델의 입력층과 출력층\n",
    "- 입력층\n",
    "    - 숫자 인덱스를 밀집 벡터로 매핑하는 embedding층\n",
    "    - (샘플, 시퀀스길이)를 입력 인자로 받음\n",
    "    - 크기가 (샘플, 시퀀스 길이, 임베딩 차원)인 3D 실수 텐서를 출력함.\n",
    "- 출력층\n",
    "    - 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 출력층\n",
    "    - 확률(0과 1 사이의 점수, 1에 가까울수록 긍정, 0에 가까울 수록 부정)을 출력하기 위해 시그모이드 활성화 함수(로지스틱 함수, vanishing gradient 문제가 있어서 현재는 잘 사용하지 않음)를 사용\n",
    "\n",
    "###  사용된 모델의 특징에 대한 기술 \n",
    "- rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 컴파일.\n",
    "- LSTM 층으로 모델을 구성하여 기존의 완전연결 네트워크보다 나은 결과를 기대.\n",
    "- 다만 하이퍼파라미터를 지정하지 않았으므로(기본값 사용) 매우 큰 차이는 기대하기 힘듬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=20000)\n",
    "\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "text_max_words = 200\n",
    "\n",
    "#훈련셋, 검증셋 지정\n",
    "input_val = input_train[max_features:]\n",
    "y_val = y_train[max_features:]\n",
    "input_train = input_train[:max_features]\n",
    "y_train = y_train[:max_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=text_max_words)\n",
    "input_val = sequence.pad_sequences(input_val, maxlen=text_max_words)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=text_max_words)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=25,\n",
    "                    batch_size=128,\n",
    "                    )\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
