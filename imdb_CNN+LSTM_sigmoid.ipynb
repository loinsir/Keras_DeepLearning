{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "imdb_CNN+LSTM_sigmoid.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt_SEt6_0M4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92995d21-5cab-4201-e341-ee47bc10855e"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFm8P9-c0M4k",
        "colab_type": "text"
      },
      "source": [
        "# IMDB 데이터 셋\n",
        "\n",
        "### 데이터셋 정보\n",
        "- 훈련 데이터와 테스트 데이터가 각각 25000개\n",
        "- 데이터의 각 review에는 label이 붙어 있다.\n",
        "- 부정은 0, 긍정은 1로 나타낸다.\n",
        "- 약 50%는 긍정, 50%는 부정 리뷰로 구성\n",
        "- review 문장의 단어들을 출현빈도순으로 정렬해서 정수로 변환시킨 시퀀스를 x로 한다.\n",
        "- 스탠포드 대학의 앤드류 마스가 수집했다.\n",
        "\n",
        "### 예측하고자 하는 방법\n",
        "- 이진 분류 문제로, 학습 데이터를 이용해, 설계한 신경망을 학습시킨다.\n",
        "- 학습된 신경망을 이용해 어떤 리뷰가 긍정일 확률을 예측할 수 있도록 한다.\n",
        "\n",
        "### 학습을 위해 데이터가 어떻게 가공/처리 되었는지?\n",
        "- 25000개의 샘플을 훈련셋 20000개와 5000개의 검증셋으로 분리\n",
        "- 길이를 맞추기 위해 패딩 삽입\n",
        "- 임베딩 층을 통과하여 실수 텐서로 매핑\n",
        "- Embedding층, conv1D층, Dropout층, LSTM, Dense층을 차례로 통과하며 모델 훈련\n",
        "\n",
        "### 사용된 모델의 입력층과 출력층\n",
        "- 입력층\n",
        "    - 숫자 인덱스를 밀집 벡터로 매핑하는 embedding층\n",
        "    - (샘플, 시퀀스길이)를 입력 인자로 받음\n",
        "    - 크기가 (샘플, 시퀀스 길이, 임베딩 차원)인 3D 실수 텐서를 출력함.\n",
        "- 출력층\n",
        "    - 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 출력층 dense, 은닉 유닛은 1\n",
        "    - 확률(0과 1 사이의 점수, 1에 가까울수록 긍정, 0에 가까울 수록 부정)을 출력하기 위해 시그모이드 활성화 함수(로지스틱 함수, vanishing gradient 문제가 있어서 현재는 잘 사용하지 않음)를 사용\n",
        "\n",
        "###  사용된 모델의 특징에 대한 기술 \n",
        "- rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 컴파일.\n",
        "- dropout층을 사용하여 과대적합 방지\n",
        "- conv1D층의 출력을 maxpooling층을 통과하며 feature 벡터를 줄임.\n",
        "- LSTM 층으로 모델을 구성하여 기존의 완전연결 네트워크보다 나은 결과를 기대."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmCthiDK0M4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b53524e5-4039-4bb1-a3a7-1881c311d1b7"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "\n",
        "max_features = 10000\n",
        "text_max_words = 500\n",
        "\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old\n",
        "#예제 실행시 오류나서 스택오버플로우사이트 참고했습니다.\n",
        "#https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56062555"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZoimPfJ0M4n",
        "colab_type": "text"
      },
      "source": [
        "#### 신경망 모델 제작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgySXIu0M4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e2ec9432-62ce-4ec8-e757-b266b1169702"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 128, input_length=text_max_words))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv1D(256,\n",
        "                 3,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(layers.MaxPooling1D(pool_size=4))\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 12:46:35.008391 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 12:46:35.190157 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 12:46:35.196401 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0805 12:46:35.237412 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0805 12:46:35.248463 139943600211840 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0805 12:46:35.304833 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IvR3MPg00M4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "bc44c1d7-d047-4cf1-a5af-351e8cef1bca"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 12:46:35.590883 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0805 12:46:35.615310 139943600211840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0805 12:46:35.620795 139943600211840 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7omwBwyj0M4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT13ebx10M4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_hJGuYD0M4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "x_val = x_train[20000:]\n",
        "y_val = y_train[20000:]\n",
        "x_train = x_train[:20000]\n",
        "y_train = y_train[:20000]\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=text_max_words)\n",
        "x_val = sequence.pad_sequences(x_val, maxlen=text_max_words)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=text_max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUyOKGIR0M4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef7d127f-b281-490e-c058-96bfff3e429b"
      },
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=25,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "20000/20000 [==============================] - 264s 13ms/step - loss: 0.4342 - acc: 0.7973 - val_loss: 0.3819 - val_acc: 0.8322\n",
            "Epoch 2/25\n",
            "20000/20000 [==============================] - 255s 13ms/step - loss: 0.2501 - acc: 0.9016 - val_loss: 0.2700 - val_acc: 0.8906\n",
            "Epoch 3/25\n",
            "20000/20000 [==============================] - 390s 19ms/step - loss: 0.1926 - acc: 0.9272 - val_loss: 0.3084 - val_acc: 0.8922\n",
            "Epoch 4/25\n",
            "20000/20000 [==============================] - 548s 27ms/step - loss: 0.1505 - acc: 0.9454 - val_loss: 0.3826 - val_acc: 0.8654\n",
            "Epoch 5/25\n",
            "20000/20000 [==============================] - 525s 26ms/step - loss: 0.1218 - acc: 0.9585 - val_loss: 0.3243 - val_acc: 0.8900\n",
            "Epoch 6/25\n",
            "20000/20000 [==============================] - 536s 27ms/step - loss: 0.0949 - acc: 0.9675 - val_loss: 0.3475 - val_acc: 0.8820\n",
            "Epoch 7/25\n",
            "20000/20000 [==============================] - 541s 27ms/step - loss: 0.0700 - acc: 0.9777 - val_loss: 0.3788 - val_acc: 0.8802\n",
            "Epoch 8/25\n",
            "20000/20000 [==============================] - 538s 27ms/step - loss: 0.0515 - acc: 0.9842 - val_loss: 0.3939 - val_acc: 0.8822\n",
            "Epoch 9/25\n",
            "20000/20000 [==============================] - 508s 25ms/step - loss: 0.0382 - acc: 0.9887 - val_loss: 0.4639 - val_acc: 0.8712\n",
            "Epoch 10/25\n",
            "20000/20000 [==============================] - 348s 17ms/step - loss: 0.0261 - acc: 0.9928 - val_loss: 0.5296 - val_acc: 0.8784\n",
            "Epoch 11/25\n",
            "20000/20000 [==============================] - 254s 13ms/step - loss: 0.0201 - acc: 0.9947 - val_loss: 0.5785 - val_acc: 0.8698\n",
            "Epoch 12/25\n",
            "20000/20000 [==============================] - 266s 13ms/step - loss: 0.0153 - acc: 0.9961 - val_loss: 0.5804 - val_acc: 0.8774\n",
            "Epoch 13/25\n",
            "20000/20000 [==============================] - 266s 13ms/step - loss: 0.0110 - acc: 0.9976 - val_loss: 0.6192 - val_acc: 0.8740\n",
            "Epoch 14/25\n",
            "20000/20000 [==============================] - 266s 13ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.6684 - val_acc: 0.8748\n",
            "Epoch 15/25\n",
            "20000/20000 [==============================] - 263s 13ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.7004 - val_acc: 0.8626\n",
            "Epoch 16/25\n",
            "20000/20000 [==============================] - 242s 12ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.7817 - val_acc: 0.8740\n",
            "Epoch 17/25\n",
            "20000/20000 [==============================] - 235s 12ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.6915 - val_acc: 0.8710\n",
            "Epoch 18/25\n",
            "20000/20000 [==============================] - 250s 12ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.8035 - val_acc: 0.8752\n",
            "Epoch 19/25\n",
            "20000/20000 [==============================] - 265s 13ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.8442 - val_acc: 0.8728\n",
            "Epoch 20/25\n",
            "20000/20000 [==============================] - 248s 12ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.8855 - val_acc: 0.8712\n",
            "Epoch 21/25\n",
            "20000/20000 [==============================] - 239s 12ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.9970 - val_acc: 0.8734\n",
            "Epoch 22/25\n",
            "20000/20000 [==============================] - 249s 12ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.9901 - val_acc: 0.8746\n",
            "Epoch 23/25\n",
            "20000/20000 [==============================] - 239s 12ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.0312 - val_acc: 0.8730\n",
            "Epoch 24/25\n",
            "20000/20000 [==============================] - 240s 12ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.9320 - val_acc: 0.8702\n",
            "Epoch 25/25\n",
            "20000/20000 [==============================] - 246s 12ms/step - loss: 4.3766e-04 - acc: 0.9998 - val_loss: 1.2847 - val_acc: 0.8632\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 498, 256)          98560     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 124, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,575,809\n",
            "Trainable params: 1,575,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}