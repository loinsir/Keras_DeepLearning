{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# IMDB 데이터셋\n",
    "\n",
    "### 데이터셋 정보\n",
    "- 훈련 데이터와 테스트 데이터가 각각 25000개\n",
    "- 데이터의 각 review에는 label이 붙어 있다.\n",
    "- 부정은 0, 긍정은 1로 나타낸다.\n",
    "- 약 50%는 긍정, 50%는 부정 리뷰로 구성\n",
    "- review 문장의 단어들을 출현빈도순으로 정렬해서 정수로 변환시킨 시퀀스를 x로 한다.\n",
    "- 스탠포드 대학의 앤드류 마스가 수집했다.\n",
    "\n",
    "### 예측하고자 하는 방법\n",
    "\n",
    "- 이진 분류 문제로, 학습 데이터를 이용해, 설계한 신경망을 학습시킨다.\n",
    "- 크로스엔트로피를 이용해 원본 분포와 예측 분포 사이를 측정한다.\n",
    "- rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 설정\n",
    "- 학습된 신경망을 이용해 어떤 리뷰가 긍정일 확률을 예측할 수 있도록 한다.\n",
    "\n",
    "### 학습을 위해 데이터가 어떻게 가공/처리 되었는지?\n",
    "- 25000개의 샘플을 훈련셋 20000개와 5000개의 검증셋으로 분리\n",
    "- 길이를 맞추기 위해 패딩 삽입\n",
    "- 임베딩 층을 통과하여 실수 텐서로 매핑\n",
    "    \n",
    "### 사용된 모델의 입력층과 출력층\n",
    "\n",
    "- 입력층\n",
    "    - 숫자 인덱스를 밀집 벡터로 매핑하는 embedding층\n",
    "    - (샘플, 시퀀스길이)를 입력 인자로 받음\n",
    "    - 크기가 (샘플, 시퀀스 길이, 임베딩 차원)인 3D 실수 텐서를 출력함.\n",
    "- 출력층\n",
    "    - 은닉 유닛이 1인 dense층\n",
    "\n",
    "###  사용된 모델의 특징에 대한 기술 \n",
    "- rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 컴파일.\n",
    "- conv1D 층을 사용하여 한 원소의 앞뒤 원소들을 확인해 큰 feature를 뽑아냄\n",
    "- GlobalMaxPooling이 conv1D층에서 나오는 feature를 받아 가장 큰 벡터하나를 뽑아내줌\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "max_features = 10000\n",
    "text_max_words = 500\n",
    "\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "#예제 실행시 오류나서 스택오버플로우사이트 참고했습니다.\n",
    "#https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56062555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_val = x_train[20000:]\n",
    "y_val = y_train[20000:]\n",
    "x_train = x_train[:20000]\n",
    "y_train = y_train[:20000]\n",
    "\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=text_max_words)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=text_max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=text_max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 모델 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 20:55:43.598358  5688 deprecation_wrapper.py:119] From C:\\Users\\a9327\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 194, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 97, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 91, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,595,937\n",
      "Trainable params: 2,595,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(20000, 128, input_length=200))\n",
    "model.add(layers.Conv1D(32,\n",
    "                 7,\n",
    "                 activation='relu'))\n",
    "model.add(layers.MaxPooling1D())\n",
    "model.add(layers.Conv1D(32,\n",
    "                 7,\n",
    "                 activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=25,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
